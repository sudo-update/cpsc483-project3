{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2724f442",
   "metadata": {},
   "source": [
    "Project 3<br> Sean Javiya<br> Jake Wong<br> Timothy Jan<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2904e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b6a66",
   "metadata": {},
   "source": [
    "Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc10c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bank-additional/bank-additional-full.csv', delimiter=';')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b709200",
   "metadata": {},
   "source": [
    "Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f82701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, train_size=0.9, random_state=(2021-10-25), shuffle=True, stratify=None)\n",
    "test = test.drop(columns='duration')\n",
    "train = train.drop(columns='duration')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a0cd",
   "metadata": {},
   "source": [
    "Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeed0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.pop('y')\n",
    "y_train = train.pop('y')\n",
    "\n",
    "categorical_test_data = test.iloc[:, :7]\n",
    "categorical_train_data = train.iloc[:, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b86098",
   "metadata": {},
   "source": [
    "Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d190044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(categorical_test_data, drop_first=True) \n",
    "train_df = pd.get_dummies(categorical_train_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9f884",
   "metadata": {},
   "source": [
    "Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18d404d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test percentage correct:  0.8788540907987376\n",
      "train percentage correct:  0.8818689470986538\n"
     ]
    }
   ],
   "source": [
    "nbfit = CategoricalNB()\n",
    "nbfit.fit(train_df, y_train)\n",
    "nb_prediction = nbfit.predict(test_df)\n",
    "#print(nb_prediction.len)\n",
    "#print(y_test)\n",
    "testscore = 0\n",
    "for index, value in enumerate(y_test):\n",
    "    if value == nb_prediction[index]:\n",
    "        testscore += 1\n",
    "#print(testscore/len(y_test))\n",
    "percentage_score = testscore/len(y_test)\n",
    "print(\"test percentage correct: \", percentage_score)\n",
    "\n",
    "nb_train_prediction = nbfit.predict(train_df)\n",
    "trainscore = 0\n",
    "for index, value in enumerate(y_train):\n",
    "    if value == nb_train_prediction[index]:\n",
    "        trainscore += 1\n",
    "#print(trainscore/len(y_train))\n",
    "percentage_train_score = trainscore/len(y_train) \n",
    "print(\"train percentage correct: \", percentage_train_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847e55d",
   "metadata": {},
   "source": [
    "Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560094f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  78  categories for age in the entire data.  This is unreasonable.\n"
     ]
    }
   ],
   "source": [
    "#print(data.age)\n",
    "unique_ages = len(set(data.age))\n",
    "print(\"There are \", unique_ages, \" categories for age in the entire data.  This is unreasonable.\")\n",
    "# should we do train and test age too?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14baebd",
   "metadata": {},
   "source": [
    "Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1eca48a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in range(len(categorical_test_data)):\n",
    "#    match int(int(categorical_test_data.age[i:i+1])/10):\n",
    "#        case 1:\n",
    "#            categorical_test_data.age[i:i+1] == 'teen'\n",
    "#        case 2:\n",
    "#            categorical_test_data.age[i:i+1] == 'twenty'\n",
    "\n",
    "#    if int(int(categorical_test_data.age[i:i+1])/10) == 1\n",
    "#        categorical_test_data.age[i:i+1] == 'teen'\n",
    "\n",
    "age_dict = {1:\"tens\",2:\"twenties\",3:\"thirties\",4:\"forties\",5:\"fifties\",6:\"sixties\",7:\"seventies\",8:\"eighties\",9:\"nineties\"}\n",
    "for ind in categorical_test_data.index:\n",
    "    decade_value = int(categorical_test_data['age'][ind]/10)\n",
    "    categorical_test_data['age'][ind] = age_dict[decade_value]\n",
    "for ind in categorical_train_data.index:\n",
    "    decade_value = int(categorical_train_data['age'][ind]/10)\n",
    "    categorical_train_data['age'][ind] = age_dict[decade_value]\n",
    "test_df_generations = pd.get_dummies(categorical_test_data, drop_first=True)\n",
    "train_df_generations = pd.get_dummies(categorical_train_data, drop_first=True)\n",
    "\n",
    "test_df_generations['age_nineties'] = 0 #preprocessing to add column of 0's for equal number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7c3858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test percentage correct:  0.6448167030832727\n",
      "train percentage correct:  0.8808168550540884\n"
     ]
    }
   ],
   "source": [
    "nbfit_generations = CategoricalNB()\n",
    "nbfit_generations.fit(train_df_generations, y_train)\n",
    "nb_prediction_generations = nbfit_generations.predict(test_df_generations)\n",
    "\n",
    "testscore = 0\n",
    "for index, value in enumerate(y_test):\n",
    "    if value == nb_prediction_generations[index]:\n",
    "        testscore += 1\n",
    "\n",
    "percentage_score_generations = testscore/len(y_test)\n",
    "print(\"test percentage correct: \", percentage_score_generations)\n",
    "\n",
    "nb_train_prediction_generations = nbfit_generations.predict(train_df_generations)\n",
    "trainscore = 0\n",
    "for index, value in enumerate(y_train):\n",
    "    if value == nb_train_prediction_generations[index]:\n",
    "        trainscore += 1\n",
    "\n",
    "percentage_train_score_generations = trainscore/len(y_train) \n",
    "print(\"train percentage correct: \", percentage_train_score_generations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1449a0d",
   "metadata": {},
   "source": [
    "Experiment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd007653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test percentage correct:  0.8771546491866958\n",
      "train percentage correct:  0.8903935903315439\n"
     ]
    }
   ],
   "source": [
    "categorical_test_data_knn = test.iloc[:, :7]\n",
    "categorical_train_data_knn = train.iloc[:, :7]\n",
    "test_df_knn = pd.get_dummies(categorical_test_data_knn, drop_first=True) \n",
    "train_df_knn = pd.get_dummies(categorical_train_data_knn, drop_first=True)\n",
    "KNNfit = KNeighborsClassifier()\n",
    "KNNfit.fit(train_df_knn, y_train)\n",
    "kn_prediction = KNNfit.predict(test_df_knn)\n",
    "testscore = 0\n",
    "for index, value in enumerate(y_test):\n",
    "    if value == kn_prediction[index]:\n",
    "        testscore += 1\n",
    "percentage_score_knn = testscore/len(y_test)\n",
    "print(\"test percentage correct: \", percentage_score_knn)\n",
    "\n",
    "kn_train_prediction = KNNfit.predict(train_df_knn)\n",
    "trainscore = 0\n",
    "for index, value in enumerate(y_train):\n",
    "    if value == kn_train_prediction[index]:\n",
    "        trainscore += 1\n",
    "\n",
    "percentage_train_score_knn = trainscore/len(y_train) \n",
    "print(\"train percentage correct: \", percentage_train_score_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e2c25",
   "metadata": {},
   "source": [
    "Experiment 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4b91b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 3646, 'yes': 473}\n",
      "test percentage correct if we assume there are no subscribed customers:  0.965768390386016\n",
      "train percentage correct if we assume there are no subscribed customers:  0.9718363052685532\n"
     ]
    }
   ],
   "source": [
    "counts = y_test.value_counts().to_dict()\n",
    "print(counts)\n",
    "testscore = 0\n",
    "for index in range(len(kn_prediction)):\n",
    "    if kn_prediction[index] == 'no':\n",
    "        testscore += 1\n",
    "\n",
    "percentage_score_knn = testscore/len(y_test)\n",
    "print(\"test percentage correct if we assume there are no subscribed customers: \", percentage_score_knn)\n",
    "\n",
    "testscore = 0\n",
    "for index in range(len(kn_train_prediction)):\n",
    "    if kn_train_prediction[index] == 'no':\n",
    "        testscore += 1\n",
    "\n",
    "percentage_score_knn_train = testscore/len(y_train)\n",
    "print(\"train percentage correct if we assume there are no subscribed customers: \", percentage_score_knn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422a7f3",
   "metadata": {},
   "source": [
    "Experiment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f2acd5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When assuming no customers are subscribed, we can compare to the actual training data to \n",
      "create the confusion matrix: \n",
      " [[32902     0]\n",
      " [ 4167     0]] \n",
      "and its AUC is:\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "#zeros like output of ^ \n",
    "zeros_dumb = pd.DataFrame(np.zeros_like(kn_train_prediction))\n",
    "y_train_binary = pd.DataFrame(np.where(y_train.values == 'yes', 1, 0),y_train.index)\n",
    "nos_like = pd.DataFrame(np.where(y_train.values == 'yes', 'no', 'no'),y_train.index)\n",
    "ConfusionMatrix_Dumb = confusion_matrix(y_true= y_train, y_pred= nos_like)\n",
    "RocAuc_score = roc_auc_score(y_train_binary, zeros_dumb)\n",
    "print(\"When assuming no customers are subscribed, we can compare to the actual training data to \\n\"\n",
    "      \"create the confusion matrix: \\n\"\n",
    "      , ConfusionMatrix_Dumb,\n",
    "      \"\\nand its AUC is:\\n\"\n",
    "      , RocAuc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d4d12",
   "metadata": {},
   "source": [
    "Experiment 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f17c72c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using the generations model from Experiment 7, we can compare to the actual training data to \n",
      "create the confusion matrix: \n",
      " [[32219   683]\n",
      " [ 3735   432]] \n",
      "and its AUC is:\n",
      " 0.5414565448830108\n",
      "\n",
      "\n",
      "When using the KNN model from Experiment 8, we can compare to the actual training data to \n",
      "create the confusion matrix: \n",
      " [[32432   470]\n",
      " [ 3593   574]] \n",
      "and its AUC is:\n",
      " 0.5617320670877847\n"
     ]
    }
   ],
   "source": [
    "nb_train_predictions_generations_binary = pd.DataFrame(np.where(pd.DataFrame(nb_train_prediction_generations).values == 'yes', 1, 0),pd.DataFrame(nb_train_prediction_generations).index)\n",
    "ConfusionMatrix_generations = confusion_matrix(y_true= y_train, y_pred= nb_train_prediction_generations)\n",
    "RocAuc_score_generations = roc_auc_score(y_train_binary, nb_train_predictions_generations_binary)\n",
    "print(\"When using the generations model from Experiment 7, we can compare to the actual training data to \\n\"\n",
    "      \"create the confusion matrix: \\n\"\n",
    "      , ConfusionMatrix_generations,\n",
    "      \"\\nand its AUC is:\\n\"\n",
    "      , RocAuc_score_generations)\n",
    "\n",
    "kn_train_prediction_binary = pd.DataFrame(np.where(pd.DataFrame(kn_train_prediction).values == 'yes', 1, 0),pd.DataFrame(kn_train_prediction).index)\n",
    "ConfusionMatrix_kn = confusion_matrix(y_true= y_train, y_pred= kn_train_prediction)\n",
    "RocAuc_score_kn = roc_auc_score(y_train_binary, kn_train_prediction_binary)\n",
    "print(\"\\n\\nWhen using the KNN model from Experiment 8, we can compare to the actual training data to \\n\"\n",
    "      \"create the confusion matrix: \\n\"\n",
    "      , ConfusionMatrix_kn,\n",
    "      \"\\nand its AUC is:\\n\"\n",
    "      , RocAuc_score_kn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec9cf0",
   "metadata": {},
   "source": [
    "Experiment 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5f2546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of yes and no values after balancing the training set:\n",
      " {'no': 32902, 'yes': 32836}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_add_y = pd.concat([train_df, y_train], axis= 1)\n",
    "train_add_y\n",
    "yes_data = train_add_y.where(cond= train_add_y.y=='yes')\n",
    "yes_data = yes_data.dropna(axis= 0, how= 'all')\n",
    "     #yes_data #8.88 x less than data\n",
    "over_sample = yes_data.sample(frac=1, random_state=(2021-10-25))\n",
    "over_sample_part = yes_data.sample(frac=0.88, random_state=(2021-10-25))\n",
    "balanced_train = pd.concat([train_add_y, over_sample, over_sample, over_sample, over_sample, over_sample, over_sample, over_sample_part], axis = 0)\n",
    "counts = balanced_train.y.value_counts().to_dict()\n",
    "print(\"Number of yes and no values after balancing the training set:\\n\", counts)\n",
    "\n",
    "#balanced_train.age[0] = age_dict[int(balanced_train.age[0].astype(int)/10)]\n",
    "balanced_train.age[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e780b",
   "metadata": {},
   "source": [
    "Experiment 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941d8893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 15",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2c7a9e52fffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_train_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdecade_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbalanced_train_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(decade_value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdecade_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecade_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 15"
     ]
    }
   ],
   "source": [
    "#y_balanced_train = balanced_train.pop('y')\n",
    "balanced_train_gen = balanced_train.copy(deep=True)\n",
    "print(balanced_train_gen.age[14])\n",
    "#age_dict = {1:\"tens\",2:\"twenties\",3:\"thirties\",4:\"forties\",5:\"fifties\",6:\"sixties\",7:\"seventies\",8:\"eighties\",9:\"nineties\"}\n",
    "for ind in range(len(balanced_train_gen)):\n",
    "    print(ind)\n",
    "    decade_value = (balanced_train_gen.age[ind]/10)\n",
    "    #print(decade_value)\n",
    "    decade_value = int(decade_value)\n",
    "    #print(decade_value)\n",
    "    decade_value = age_dict[decade_value]\n",
    "    #print(ind)\n",
    "    balanced_train_gen.age[ind] = decade_value\n",
    "    \n",
    "balanced_train_gen\n",
    "#for ind in balanced_train_gen.index:\n",
    "#    decade_value = int(balanced_train_gen['age'][ind]/10)\n",
    "#    balanced_train_gen['age'][ind] = age_dict[decade_value]\n",
    "\n",
    "#test_gen = pd.get_dummies(test, drop_first=True)\n",
    "#balanced_train_gen = pd.get_dummies(balanced_train_gen, drop_first=True)\n",
    "\n",
    "#test_gen['age_nineties'] = 0 #preprocessing to add column of 0's for equal number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78081d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
